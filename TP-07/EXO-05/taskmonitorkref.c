#include "taskmonitorkref.h"static int target = 0;module_param(target, int, 0660);static struct task_monitor *monitored = NULL;static struct task_struct *monitor_thread;static unsigned interval = 5; /* interval between reports in seconds */static unsigned frequency = HZ; /* samples frequency */static mempool_t * memp;static struct kmem_cache * task_sample_cache = NULL;	//KMEM_CACHE(task_sample, SLAB_PANIC | SLAB_NOTRACK);static struct shrinker sh = {	.count_objects = task_count_objects,	.scan_objects = task_scan_objects,	.seeks = DEFAULT_SEEKS,	.batch = 0,	.flags = 0};static struct kobj_attribute kobj_attr = __ATTR_RO(taskmonitor);static ssize_t taskmonitor_show(struct kobject *kobj,		struct kobj_attribute *attr, char *buf){	// 50 by line	// Max total PAGE_SIZE / 50	// list_reverse	int nb_max_sample = PAGE_SIZE / 50;	int i = 0;	int offset = 0;	struct list_head * tmp;	struct list_head * tmp_scie;	//mutex_lock(&(monitored->m));	list_for_each_safe(tmp_scie, tmp, &(monitored->head)) {		struct task_sample *proc = container_of(tmp_scie, struct task_sample, list);		if(kref_get_unless_zero(&proc->ref)){			if (i < nb_max_sample){				offset += scnprintf(buf+offset, 50, "pid %d : %llu usr %llu sys \n", 					target, proc->utime, proc->stime);			}			kref_put(&proc->ref, free_task_sample);		}	}	//mutex_unlock(&(monitored->m));	return offset;}static ssize_t taskmonitor_store(struct kobject *kobj,		struct kobj_attribute *attr, const char *buf,			size_t count){	pr_warn("Taskmonitor store\n");	if (monitor_thread != NULL && strncmp(buf, "stop", 4) == 0) {		pr_warn("Taskmonitor store stop\n");		kthread_stop(monitor_thread);		monitor_thread = NULL;	} else if (monitor_thread == NULL && strncmp(buf, "start", 5) == 0) {		pr_warn("Taskmonitor store start\n");		monitor_thread = kthread_run(monitor_fn, NULL, "monitor_fn");	}	return count;}static void free_task_sample(struct kref *kref){	struct task_sample *task = container_of(kref, struct task_sample, ref);	kmem_cache_free(task_sample_cache, task);}static unsigned long task_scan_objects(struct shrinker * sh, struct shrink_control *sc){	struct list_head *tmp;	struct list_head *tmp_scie;	int nb_free=0;	pr_warn("scan func \n");	pr_warn("Kern need %lu to free \n", sc->nr_to_scan);	//mutex_lock(&(monitored->m));	list_for_each_safe(tmp_scie, tmp,&(monitored->head)) {		struct task_sample *proc = container_of(tmp_scie, struct task_sample, list);		if(kref_get_unless_zero(&proc->ref)){			list_del(tmp_scie);			nb_free++;			monitored->nb_samples--;			kref_put(&proc->ref, free_task_sample);			if(nb_free >= sc->nr_to_scan)				break;		}			}	//mutex_unlock(&(monitored->m));	return nb_free;}static unsigned long task_count_objects(struct shrinker * sh, struct shrink_control *sc){	int out = monitored->nb_samples - 3;	return (out > 0)?out:0;}static bool get_sample(struct task_sample *sample){	if (pid_alive(monitored->proc) == 1) {		sample->utime = monitored->proc->utime;		sample->stime = monitored->proc->stime;		kref_init(&sample->ref);		return 1;	}	return 0;}static bool save_sample(void){	//struct task_sample * task_s = kmalloc(sizeof(*task_s), GFP_KERNEL);	struct task_sample * task_s = kmem_cache_alloc(task_sample_cache, GFP_KERNEL);	if(task_s != NULL && get_sample(task_s)){		//mutex_lock(&(monitored->m));		list_add_tail((&(task_s->list)),  (&(monitored->head)));		monitored->nb_samples++;		//mutex_unlock(&(monitored->m));		pr_warn("pid %d : %llu usr %llu sys (nÂ°%d size = %lu)\n", target,			task_s->utime, task_s->stime, monitored->nb_samples, sizeof(*task_s));		return 0;	}		return 1;}static int monitor_fn(void *data){	//struct task_sample sample;	int n = 0;	pr_info("Thread starting.\n");	while (!kthread_should_stop()) {		if (++n % (interval * (HZ / frequency)) == 0) {			if(save_sample()){				pr_warn("Thread fault.\n");				break;			}		}							set_current_state(TASK_UNINTERRUPTIBLE);		schedule_timeout(frequency);	}	return 0;}static int monitor_pid(pid_t pid){	struct pid *pid_found = find_get_pid(pid);	if (pid_found == NULL) {		pr_warn("PID not found\n");		return -1;	}	monitored = kmalloc(sizeof(*monitored), GFP_KERNEL);	monitored->pid = pid_found;	INIT_LIST_HEAD(&(monitored->head));	monitored->nb_samples = 0;	mutex_init(&(monitored->m));	monitored->proc = get_pid_task(monitored->pid, PIDTYPE_PID);	return 0;}static int __init taskmonitor_init(void){	pr_info("Hello, taskmonitor\n");	if (monitor_pid(target))		goto ERROR1;	if (sysfs_create_file(kernel_kobj, &(kobj_attr.attr)))		goto ERROR2;	task_sample_cache = KMEM_CACHE(task_sample, SLAB_PANIC);	memp = mempool_create(10, mempool_alloc_slab, mempool_free_slab, task_sample_cache);	if (!memp)		goto ERROR3;	if (register_shrinker(&sh))		goto ERROR4;	monitor_thread = kthread_run(monitor_fn, NULL, "monitor_fn");	pr_info("Module taskmonitor successfully loaded.\n");	return 0;ERROR4:	mempool_destroy(memp);ERROR3:	sysfs_remove_file(kernel_kobj, &(kobj_attr.attr));ERROR2:	free_monitored();ERROR1:	pr_info("Module taskmonitor failed to load.\n");	return -1;}static void __exit taskmonitor_exit(void){	struct list_head * tmp;	struct list_head * tmp_scie;		pr_info("Bye, taskmonitor\n");	if (monitor_thread)		kthread_stop(monitor_thread);	//  list_del(&(monitored->head));	if (monitored != NULL) {		list_for_each_safe(tmp_scie, tmp,&(monitored->head)) {			struct task_sample * proc = container_of(tmp_scie, struct task_sample, list);			if(kref_get_unless_zero(&proc->ref)){								list_del(tmp_scie);				//kfree(proc);				kmem_cache_free(task_sample_cache, proc);				kref_put(&proc->ref, free_task_sample);			}		}	}	free_monitored();		mempool_destroy(memp);	unregister_shrinker(&sh);	sysfs_remove_file(kernel_kobj, &(kobj_attr.attr));}static void free_monitored(void){	if (!monitored)		return;	put_task_struct(monitored->proc);	put_pid(monitored->pid);	kfree(monitored);}
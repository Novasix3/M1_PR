#include "taskmonitormulti.h"static int target = 0;module_param(target, int, 0660);//static struct task_monitor *monitored = NULL;static struct task_struct *monitor_thread;static unsigned interval = 5; /* interval between reports in seconds */static unsigned frequency = HZ; /* samples frequency */static mempool_t * memp;static int elem_to_keep = 5;static struct kmem_cache * task_sample_cache = NULL;	//KMEM_CACHE(task_sample, SLAB_PANIC | SLAB_NOTRACK);static struct shrinker sh = {	.count_objects = task_count_objects,	.scan_objects = task_scan_objects,	.seeks = DEFAULT_SEEKS,	.batch = 0,	.flags = 0};static struct kobj_attribute kobj_attr = __ATTR_RO(taskmonitor);static struct file_operations ct_file_ops = {        .owner   = THIS_MODULE,        .open    = debugfs_open,        .read    = seq_read,        .llseek  = seq_lseek,        .release = seq_release,  	.write 	 = debugfs_write};static struct dentry *debug_file;static LIST_HEAD(my_head);static struct mutex bigfatlock;static ssize_t debugfs_write(struct file *file, const char *buf, size_t count, loff_t *ppos) {	char * buffer  =  kmalloc(count, GFP_KERNEL);	struct list_head *tmp;	struct list_head *tmp_scie;	struct task_monitor * tm;	struct list_head *tmp_monit;	struct list_head *tmp_monit_int;	int pid = 0;	if(buffer == NULL){		printk (KERN_WARNING "problème kmalloc !\n" );		return -ENOMEM;	}	if(copy_from_user(buffer,buf,count+1)){		printk (KERN_WARNING "problème copy_from_user !\n" );		return -ENOMEM;	}	if(buffer[0] == '-'){		if(kstrtoint_from_user(buf+1, count, 10, &pid)<0){			pr_warn("PB\n");		}		pr_warn("Remove PID %d \n", pid);		mutex_lock(&bigfatlock);		list_for_each_safe(tmp_monit, tmp_monit_int, &my_head) {			tm = container_of(tmp_monit, struct task_monitor, monitored);			if(pid_vnr(tm->pid) == pid){				mutex_lock(&tm->m);				list_del(&(tm->monitored));				list_for_each_safe (tmp_scie, tmp, &(tm->list)) {					struct task_sample *ts = container_of(						tmp_scie, struct task_sample, list);					tm->nb_samples--;					list_del(&(ts->list));					kref_put(&(ts->ref), free_task_sample);				}				mutex_unlock(&tm->m);				free_monitored(tm);			}		}		mutex_unlock(&bigfatlock);	}else{		if(kstrtoint_from_user(buf, count, 10, &pid)<0){			pr_warn("PB\n");		}		pr_warn("Add PID %d \n", pid);		monitor_pid(pid);	}	kfree(buffer), buffer  = NULL;	return count;}static int debug_show(struct seq_file *m, void *p){	// 50 by line	// Max total PAGE_SIZE / 50	// list_reverse	struct list_head *temp_monit, *temp_sample, *cpy;	mutex_lock(&bigfatlock);	list_for_each(temp_monit, &my_head){		struct task_monitor *monit = container_of(temp_monit, 			struct task_monitor, monitored);		mutex_lock(&monit->m);		int temp = monit->pid->numbers[monit->pid->level].nr;		list_for_each_prev_safe(temp_sample, cpy, &monit->list) {			struct task_sample *proc = container_of(temp_sample, struct task_sample, list);			kref_get(&proc->ref);			seq_printf(m, "pid %d : %llu usr %llu sys \n", temp,				proc->utime, proc->stime);			kref_put(&proc->ref, free_task_sample);		}		mutex_unlock(&monit->m);	}	mutex_unlock(&bigfatlock);	return 0;}static int debugfs_open(struct inode *inode, struct file *file){	return single_open(file, debug_show, NULL);}static ssize_t taskmonitor_show(struct kobject *kobj,		struct kobj_attribute *attr, char *buf){	// 50 by line	// Max total PAGE_SIZE / 50	// list_reverse	struct list_head *temp_monit, *temp_sample, *cpy;	int offset = 0;	mutex_lock(&bigfatlock);	list_for_each(temp_monit, &my_head){		struct task_monitor *monit = container_of(temp_monit, 			struct task_monitor, monitored);		mutex_lock(&monit->m);				int temp = monit->pid->numbers[monit->pid->level].nr;		list_for_each_prev_safe(temp_sample, cpy, &monit->list) {			struct task_sample *proc = container_of(temp_sample, struct task_sample, list);			kref_get(&proc->ref);			if (offset < PAGE_SIZE){				offset += scnprintf(buf+offset, 50, "pid %d : %llu usr %llu sys \n", 					temp, proc->utime, proc->stime);			}			kref_put(&proc->ref, free_task_sample);		}		mutex_unlock(&monit->m);		if (offset >= PAGE_SIZE)			break;	}	mutex_unlock(&bigfatlock);	return offset;}static ssize_t taskmonitor_store(struct kobject *kobj,		struct kobj_attribute *attr, const char *buf,			size_t count){	pr_warn("Taskmonitor store\n");	if (monitor_thread != NULL && strncmp(buf, "stop", 4) == 0) {		pr_warn("Taskmonitor store stop\n");		kthread_stop(monitor_thread);		monitor_thread = NULL;	} else if (monitor_thread == NULL && strncmp(buf, "start", 5) == 0) {		pr_warn("Taskmonitor store start\n");		monitor_thread = kthread_run(monitor_fn, NULL, "monitor_fn");	}	return count;}static void free_task_sample(struct kref *kref){	struct task_sample *task = container_of(kref, struct task_sample, ref);	//kmem_cache_free(task_sample_cache, task);	mempool_free(task, memp);}static unsigned long task_scan_objects(struct shrinker * sh, struct shrink_control *sc){	struct list_head *temp_monit, *temp_sample, *cpy;	int nb_free=0;	pr_warn("Kernel need %lu to free \n", sc->nr_to_scan);	mutex_lock(&bigfatlock);	list_for_each(temp_monit, &my_head){		struct task_monitor *monit = container_of(temp_monit, 			struct task_monitor, monitored);		if(monit->nb_samples <= elem_to_keep)			continue;		mutex_lock(&monit->m);		list_for_each_safe(temp_sample, cpy, &monit->list) {			struct task_sample *proc = container_of(temp_sample, struct task_sample, list);			kref_get(&proc->ref);			list_del_init(temp_sample);			nb_free++;			monit->nb_samples--;			kref_put(&proc->ref, free_task_sample);			if(monit->nb_samples <= elem_to_keep)				break;					}		mutex_unlock(&monit->m);		if(nb_free >= sc->nr_to_scan)			break;	}	mutex_unlock(&bigfatlock);	sc->nr_scanned = nb_free;	return nb_free;}static unsigned long task_count_objects(struct shrinker * sh, struct shrink_control *sc){	int out = 0;	struct list_head *temp;	mutex_lock(&bigfatlock);	list_for_each(temp, &my_head){		struct task_monitor *monit = container_of(temp, 			struct task_monitor, monitored);		out += ( (monit->nb_samples > elem_to_keep)?(monit->nb_samples - elem_to_keep):0 );	}	mutex_unlock(&bigfatlock);	return out;}static struct task_sample* get_sample(struct task_monitor *monitored){	if (pid_alive(monitored->proc) == 1) {		struct task_sample *sample = mempool_alloc(memp, GFP_KERNEL);		if(!sample)			return NULL;		sample->utime = monitored->proc->utime;		sample->stime = monitored->proc->stime;		kref_init(&sample->ref);		return sample;	}	return NULL;}static bool save_sample(void){	struct list_head *temp;	mutex_lock(&bigfatlock);	list_for_each(temp, &my_head){		struct task_monitor *monit = container_of(temp, 			struct task_monitor, monitored);		struct task_sample *task_s = get_sample(monit);		if(task_s){			mutex_lock(&monit->m);			list_add_tail(&task_s->list, &monit->list);			mutex_unlock(&monit->m);			monit->nb_samples++;			int temp = monit->pid->numbers[monit->pid->level].nr;			pr_warn("pid %d : %llu usr %llu sys (n°%d size = %lu)\n", 				temp,				task_s->utime, task_s->stime, monit->nb_samples, 				sizeof(*task_s));					}else{			return 1;		}	}	mutex_unlock(&bigfatlock);			return 0;}static int monitor_fn(void *data){	//struct task_sample sample;	int n = 0;	pr_info("Thread starting.\n");	while (!kthread_should_stop()) {		if (++n % (interval * (HZ / frequency)) == 0) {			if(save_sample()){				pr_warn("Thread fault.\n");				break;			}		}					set_current_state(TASK_UNINTERRUPTIBLE);		schedule_timeout(frequency);	}	return 0;}static int monitor_pid(pid_t pid){	struct task_monitor *monitored;	struct pid *pid_found = find_get_pid(pid);	if (pid_found == NULL) {		pr_warn("PID not found\n");		return -1;	}	monitored = kmalloc(sizeof(*monitored), GFP_KERNEL);	monitored->pid = pid_found;	INIT_LIST_HEAD(&monitored->list);	monitored->nb_samples = 0;	mutex_init(&monitored->m);	monitored->proc = get_pid_task(monitored->pid, PIDTYPE_PID);	list_add(&monitored->monitored, &my_head);	return 0;}//A FAIREstatic int __init taskmonitor_init(void){	pr_info("Hello, taskmonitor\n");	if (monitor_pid(target))		goto ERROR1;	if (sysfs_create_file(kernel_kobj, &(kobj_attr.attr)))		goto ERROR2;	task_sample_cache = KMEM_CACHE(task_sample, SLAB_PANIC);	memp = mempool_create_slab_pool(elem_to_keep, task_sample_cache);	if (!memp)		goto ERROR3;	if (register_shrinker(&sh))		goto ERROR4;	debug_file = debugfs_create_file("taskmonitordebug", S_IRUGO,				       NULL, NULL, &ct_file_ops);	if (!debug_file)		goto ERROR5;	mutex_init(&bigfatlock);	monitor_thread = kthread_run(monitor_fn, NULL, "monitor_fn");	pr_info("Module taskmonitor successfully loaded.\n");	return 0;ERROR5:	unregister_shrinker(&sh);ERROR4:	mempool_destroy(memp);ERROR3:	sysfs_remove_file(kernel_kobj, &(kobj_attr.attr));ERROR2:ERROR1:	pr_info("Module taskmonitor failed to load.\n");	return -1;}static void __exit taskmonitor_exit(void){		pr_info("Bye, taskmonitor\n");	if (monitor_thread)		kthread_stop(monitor_thread);	free_lists();	kmem_cache_destroy(task_sample_cache);		mempool_destroy(memp);	unregister_shrinker(&sh);	sysfs_remove_file(kernel_kobj, &(kobj_attr.attr));	debugfs_remove(debug_file);}static void free_monitored(struct task_monitor *monitored){	if (!monitored)		return;	list_del_init(&monitored->list);	mutex_destroy(&monitored->m);	put_task_struct(monitored->proc);	put_pid(monitored->pid);	kfree(monitored);}static void free_lists(void){	struct list_head *temp_monit, *temp_sample, *cpy1, *cpy2;	mutex_lock(&bigfatlock);	list_for_each_safe(temp_monit, cpy1, &my_head){		struct task_monitor *monit = container_of(temp_monit, 			struct task_monitor, monitored);		mutex_lock(&monit->m);		list_for_each_safe(temp_sample, cpy2, &monit->list) {			struct task_sample *proc = container_of(temp_sample, struct task_sample, list);			list_del_init(temp_sample);			monit->nb_samples--;			kref_put(&proc->ref, free_task_sample);					}		mutex_unlock(&monit->m);		free_monitored(monit);	}	mutex_unlock(&bigfatlock);}